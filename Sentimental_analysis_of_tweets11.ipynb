{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sem-Enyo/Sentimental-analysis-of-tweets/blob/main/Sentimental_analysis_of_tweets11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4-WT0IQHdDl"
      },
      "outputs": [],
      "source": [
        "!pip install snscrape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siOkXGJAHVdI"
      },
      "outputs": [],
      "source": [
        "import snscrape.modules.twitter as sntwitter\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "eZaMXCttdyaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scipy"
      ],
      "metadata": {
        "id": "YP-TO95Ld82r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gbtko6hHovr"
      },
      "outputs": [],
      "source": [
        "#Extracting tweets that include 'Graham Potter' btween 29 August and 11th Sepetember\n",
        "\n",
        "query = \"Graham Potter lang:en until:2022-09-11 since:2022-08-29\"\n",
        "tweets = []\n",
        "limit = 100000\n",
        "for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
        "  if len(tweets) == limit:\n",
        "      break\n",
        "  else:\n",
        "    tweets.append([tweet.date, tweet.username, tweet.content])\n",
        "\n",
        "df = pd.DataFrame(tweets, columns=['Date', 'User', 'Tweet'])\n",
        "print(df.head())\n",
        "\n",
        "df.to_csv('tweets.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Label']=''\n",
        "df['Score']=''\n",
        "\n"
      ],
      "metadata": {
        "id": "Qh4BjKGCfj7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#In as much as out limit was 100000 tweets, the total tweets extracted was 48458 tweets\n",
        "df.tail()"
      ],
      "metadata": {
        "id": "WhRHA_os0Y-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "hmnKWe9Bw3U5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Running the converted date so as to extract just the date without the time\n",
        "\n",
        "df['New_Date']=pd.to_datetime(df['Date'],format=\"%Y-%m-%d %H:%M:%S\")\n",
        "df['New_Date'] = [d.date() for d in df['New_Date']]\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Y31gou1RxDHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del df['Date']\n",
        "df.tail()"
      ],
      "metadata": {
        "id": "QozjnGMaxLKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from scipy.special import softmax"
      ],
      "metadata": {
        "id": "CtCTs6qxgG6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roberta = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(roberta)\n",
        "tokenizer = AutoTokenizer.from_pretrained(roberta)\n",
        "\n",
        "labels = ['Negative', 'Neutral', 'Positive']\n"
      ],
      "metadata": {
        "id": "3-x0BDjykm_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCUNuy23Qsol"
      },
      "outputs": [],
      "source": [
        "#Iterating throught each tweet to detrmine what is a username and a url\n",
        "for x in range(len(df)):\n",
        "  tweet = df['Tweet'][x]\n",
        "\n",
        "  tweet_words = []\n",
        "\n",
        "  for word in tweet.split(' '):\n",
        "    if word.startswith('@') and len(word) > 1:\n",
        "        word = '@user'\n",
        "\n",
        "    elif word.startswith('http'):\n",
        "        word = \"http\"\n",
        "    tweet_words.append(word)\n",
        "\n",
        "    tweet_proc = \" \".join(tweet_words)\n",
        "    df['Tweet'][x]=tweet_proc\n",
        "\n",
        "  # sentiment analysis on each tweet\n",
        "  encoded_tweet = tokenizer(tweet_proc, return_tensors='pt')\n",
        "\n",
        "  output = model(**encoded_tweet)\n",
        "\n",
        "  scores = output[0][0].detach().numpy()\n",
        "  scores = softmax(scores)\n",
        "\n",
        "  # saving the hihest score for each tweet in the dataframe along with its label\n",
        "  max_scores = 0\n",
        "  for i in range(len(scores)):\n",
        "    if scores[i]>max_scores:\n",
        "      max_scores= scores[i]\n",
        "      label = labels[i]\n",
        "  df['Label'][x]=label\n",
        "  df['Score'][x]=max_scores\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Label'].describe()"
      ],
      "metadata": {
        "id": "IP_DReZR3z3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This was to check for any null values\n",
        "df.info()"
      ],
      "metadata": {
        "id": "b9donlg2jPr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Finally saving the dataframe as a csv file to be create a visualisation in tableau\n",
        "df.to_csv('tweets_fin.csv')"
      ],
      "metadata": {
        "id": "2UxdFUF3_6vQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Project aided by tutorials from Mehranshakarami on youtube"
      ],
      "metadata": {
        "id": "RjpeNUEVD-BE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMS8aD0JICCR0jMNYNMJXR9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}